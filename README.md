# Outlier Detection Framework (PySpark)

## Overview

This project demonstrates an end-to-end anomaly detection framework originally developed and refined as part of a professional supply chain analytics project. It showcases my expertise in building ETL pipelines, cleaning and transforming large datasets, and applying advanced outlier detection techniques. The framework integrates PySpark for scalable data processing, Pandas for data manipulation, and machine learning libraries like Scikit-learn to identify outliers using Z-Score, IQR, and Isolation Forest.

The notebook:
- Ingests and cleans transactional data, handling inconsistent formats and missing values.
- Aggregates and bins spend data to provide a comprehensive overview.
- Applies multiple anomaly detection methods to identify suspicious patterns.
- Combines detection outputs using a weighted scoring system to classify anomaly severity.
- Outputs results with summary statistics and visualisations to guide further investigation.

---

## Skills Demonstrated

✅ **ETL Pipeline Development** — end-to-end ingestion, cleaning, transformation, and aggregation of large datasets.  
✅ **Anomaly Detection** — applying Z-Score, IQR, and Isolation Forest methods to detect unusual patterns.  
✅ **PySpark** — scalable data engineering and transformation at scale.  
✅ **Pandas** — flexible data manipulation and integration with Spark outputs.  
✅ **Machine Learning** — Isolation Forest implementation using Scikit-learn.  
✅ **Data Visualisation** — distribution analysis and summary reports using Matplotlib.

---

## Why This Project Matters

This project highlights my ability to build robust, production-ready data pipelines that integrate statistical and machine learning approaches for anomaly detection in real-world datasets. It demonstrates practical skills in transforming raw data into actionable insights, essential for data-driven decision-making.
